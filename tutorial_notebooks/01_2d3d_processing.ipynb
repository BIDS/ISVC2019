{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageXD 2019 - Images across domains\n",
    "\n",
    "BIDS @ University of California, Berkeley\n",
    "\n",
    "* Support material for the tutorial _scikit-image: 3D Image Processing_.\n",
    "\n",
    "This tutorial will introduce how to analyze three dimensional stacked and volumetric\n",
    "images in Python, mainly using scikit-image. Here we will learn how to:\n",
    "  * pre-process data using filtering, binarization and segmentation techniques.\n",
    "  * inspect, count and measure attributes of objects and regions of interest in the data.\n",
    "  * visualize 3D data.\n",
    "\n",
    "Please prepare for the tutorial by [installing the pre-requisite\n",
    "software](preparation.md) beforehand.\n",
    "\n",
    "For more info:\n",
    "  * [[ImageXD 2019]](https://xd-con.org/imagexd-2019/)\n",
    "  * [[scikit-image]](https://scikit-image.org/)\n",
    "\n",
    "\n",
    "## What is scikit-image?\n",
    "\n",
    "scikit-image is a collection of image processing algorithms which aims to integrate well with for the SciPy ecosystem.\n",
    "\n",
    "It is well documented, and provides well-tested code to quickly build sophisticated image processing pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the base Scientific Python ecossystem\n",
    "\n",
    "Let's start importing the basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing some helping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supplementary_code as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's set a nice, `monospace` font for matplotlib's figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'monospace'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to two-dimensional image processing\n",
    "\n",
    "In scikit-image, images are represented as `numpy` arrays.\n",
    "\n",
    "A grayscale image is a 2D matrix of pixel intensities of shape `(row, column)`. They are also called single-channel images. Multi-channel data has an extra dimension, `channel`, in the final position. `channel` contains color information:\n",
    "\n",
    "|Image type|Coordinates|\n",
    "|:---|:---|\n",
    "|2D grayscale|(row, column)|\n",
    "|2D multichannel|(row, column, channel)|\n",
    "\n",
    "\n",
    "## [skimage.io](https://scikit-image.org/docs/stable/api/skimage.io.html) - utilities to read and write images in several formats<a id='io'></a>\n",
    "\n",
    "This module helps us on reading images and saving the results. There are multiple plugins available, which support multiple formats. The most commonly used functions include:\n",
    "\n",
    "* `io.imread`: read an image to a numpy array.\n",
    "* `io.imsave`: write an image to disk.\n",
    "* `io.imread_collection`: read multiple images which match a common pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io  # skimage's I/O submodule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be loaded with `io.imread`, as in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = io.imread('data/cells.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's check its shape, data type and range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('* \"cells\" shape: {}'.format(cells.shape))\n",
    "print('* \"cells\" type: {}'.format(cells.dtype))\n",
    "print('* \"cells\" range: {}, {}'.format(cells.min(), cells.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `cells` has 60 planes, each with 256 rows and 256 columns. Let's focus here on processing one of the planes first, which falls to the case of processing a two-dimensional image. Then, we can visualize a 2D plane using `skimage.io.imshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane = cells[32]  # using the plane 32\n",
    "io.imshow(plane, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `skimage.io.imshow` can only display grayscale and RGB(A) 2D images.\n",
    "\n",
    "## [skimage.exposure](https://scikit-image.org/docs/stable/api/skimage.exposure.html) - evaluating or changing the exposure of an image<a id='exposure'></a>\n",
    "\n",
    "This module contains a number of functions for adjusting image contrast. We will use `exposure.adjust_gamma`, which performs gamma correction in the input image.\n",
    "\n",
    "\n",
    "[Gamma correction](https://en.wikipedia.org/wiki/Gamma_correction), also known as Power Law Transform, brightens or darkens an image. The function $O = I^\\gamma$ is applied to each pixel in the image. A `gamma < 1` will brighten an image, while a `gamma > 1` will darken an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure  # skimage's exposure module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_val_low = 0.5\n",
    "plane_gamma_low = exposure.adjust_gamma(plane, gamma=gamma_val_low)\n",
    "\n",
    "gamma_val_high = 1.5\n",
    "plane_gamma_high = exposure.adjust_gamma(plane, gamma=gamma_val_high)\n",
    "\n",
    "_, ((win_top_left, win_top_center, win_top_right),\n",
    "    (win_bottom_left, win_bottom_center, win_bottom_right)) = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\n",
    "\n",
    "# Original and its histogram.\n",
    "sc.show_plane(win_top_left, plane, title='Original')\n",
    "sc.plot_hist(win_bottom_left, plane)\n",
    "\n",
    "# Gamma = 0.5 and its histogram.\n",
    "sc.show_plane(win_top_center, plane_gamma_low, title='Gamma = {}'.format(gamma_val_low))\n",
    "sc.plot_hist(win_bottom_center, plane_gamma_low)\n",
    "\n",
    "# Gamma = 1.5 and its histogram.\n",
    "sc.show_plane(win_top_right, plane_gamma_high, title='Gamma = {}'.format(gamma_val_high))\n",
    "sc.plot_hist(win_bottom_right, plane_gamma_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most experimental images are affected by salt and pepper noise. A few bright artifacts can decrease the relative intensity of the pixels of interest.\n",
    "\n",
    "A simple way to improve contrast is to clip the pixel values on the lowest and highest extremes. Here we use `exposure.rescale_intensity` for that. Clipping the darkest and brightest 0.5% of pixels will increase the overall contrast of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = np.percentile(plane, q=(0.5, 99.5))\n",
    "\n",
    "plane_clipped = exposure.rescale_intensity(\n",
    "    plane,\n",
    "    in_range=(vmin, vmax), \n",
    "    out_range=np.float32\n",
    ")\n",
    "\n",
    "# Checking the results.\n",
    "_, (win_left, win_right) = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "sc.show_plane(win_left, plane, title='Original');\n",
    "sc.show_plane(win_right, plane_clipped, title='Clipped');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll call our dataset `plane_rescaled` from now on. It will contain the plane version with clipped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_rescaled = plane_clipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__Exercise: <font color='red'>(‚è∞ 5 min)</font>__ One of the most common tools to evaluate exposure is the *histogram*, which plots the number of points which have a certain value against the values in order from lowest (dark) to highest (light).\n",
    "\n",
    "A well-known tool for that is the [Histogram equalization](https://en.wikipedia.org/wiki/Histogram_equalization), which improves contrast in an image by redistributing pixel intensities. This operation may enhance background noise, since the most common pixel intensities are spread out, allowing areas of lower local contrast to gain a higher contrast. \n",
    "\n",
    "[Adaptive histogram equalization](https://en.wikipedia.org/wiki/Adaptive_histogram_equalization), on the other hand, is suitable for improving the local contrast and enhancing the definitions of edges in each region of an image. The adaptive method computes several histograms, each corresponding to a section of the image, and uses them to redistribute its lightness values. \n",
    "\n",
    "Now, there's some tasks for you:\n",
    "  * Process `plane`'s histogram using histogram equalization, given in `exposure.equalize_hist`, and its adaptive version, from `exposure.equalize_adapthist`.\n",
    "  * Visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution goes here!\n",
    "\n",
    "# First, let's create a version using histogram equalization. \n",
    "plane_equalized = exposure.equalize_hist(...)\n",
    "\n",
    "# Now, a version using CLAHE. \n",
    "plane_clahe = exposure.equalize_adapthist(...)\n",
    "\n",
    "# Let's check the results.\n",
    "_, ((win_top_left, win_top_center, win_top_right),\n",
    "    (win_bottom_left, win_bottom_center, win_bottom_right)) = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\n",
    "\n",
    "# On the top, the 2D plots...\n",
    "sc.show_plane(win_top_left, ..., title='Original')\n",
    "sc.show_plane(win_top_center, ..., title='Histogram equalization')\n",
    "sc.show_plane(win_top_right, ..., title='CLAHE')\n",
    "\n",
    "# ... on the bottom, the histograms.\n",
    "sc.plot_hist(win_bottom_left, ...)\n",
    "sc.plot_hist(win_bottom_center, ...)\n",
    "sc.plot_hist(win_bottom_right, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge detection\n",
    "\n",
    "[Edge detection](https://en.wikipedia.org/wiki/Edge_detection) highlights regions in the image where a sharp change in contrast occurs. The intensity of an edge corresponds to the steepness of the transition from one intensity to another. A gradual shift from bright to dark intensity results in a dim edge. An abrupt shift results in a bright edge.\n",
    "\n",
    "## [skimage.filters](https://scikit-image.org/docs/stable/api/skimage.filters.html) - apply filters to an image<a id='filters'></a>\n",
    "\n",
    "Filtering applies whole-image modifications such as sharpening or blurring. In addition to edge detection, `skimage.filters` provides functions for filtering and thresholding images.\n",
    "\n",
    "Notable functions include (links to relevant gallery examples):\n",
    "\n",
    "* [Thresholding](https://scikit-image.org/docs/stable/auto_examples/applications/plot_thresholding.html):\n",
    "  * `filters.threshold_*` (multiple different functions with this prefix)\n",
    "  * `filters.try_all_threshold` to compare various methods\n",
    "* [Edge finding/enhancement](https://scikit-image.org/docs/stable/auto_examples/edges/plot_edge_filter.html):\n",
    "  * `filters.sobel` - not adapted for 3D images. It can be applied planewise to approximate a 3D result.\n",
    "  * `filters.prewitt`\n",
    "  * `filters.scharr`\n",
    "  * `filters.roberts`\n",
    "  * `filters.laplace`\n",
    "  * `filters.hessian`\n",
    "* [Ridge filters](https://scikit-image.org/docs/stable/auto_examples/edges/plot_ridge_filter.html):\n",
    "  * `filters.meijering`\n",
    "  * `filters.sato`\n",
    "  * `filters.frangi`\n",
    "* Inverse filtering (see also [skimage.restoration](#restoration)):\n",
    "  * `filters.weiner`\n",
    "  * `filters.inverse`\n",
    "* [Directional](https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_gabor.html): `filters.gabor`\n",
    "* Blurring/denoising\n",
    "  * `filters.gaussian`\n",
    "  * `filters.median`\n",
    "* [Sharpening](https://scikit-image.org/docs/stable/auto_examples/filters/plot_unsharp_mask.html): `filters.unsharp_mask`\n",
    "* Define your own filter: `LPIFilter2D`\n",
    "  \n",
    "The sub-submodule `skimage.filters.rank` contains rank filters. These filters are nonlinear and operate on the local histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters  # skimage's filtering module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Sobel operator](https://en.wikipedia.org/wiki/Sobel_operator) is an edge detection algorithm which approximates the gradient of the image intensity, and is fast to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_sobel = filters.sobel(plane_rescaled)\n",
    "\n",
    "# Checking the results.\n",
    "_, (win_left, win_right) = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "sc.show_plane(win_left, plane, title='Original');\n",
    "# setting a different map to ease visualization\n",
    "sc.show_plane(win_right, plane_sobel, title='Sobel', cmap='Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__Exercise: <font color='red'>(‚è∞ 5 min)</font>__ let's check the results of other filters.\n",
    "\n",
    "Your tasks right now are:\n",
    "  * Try the horizontal (`filters.sobel_h`) and vertical(`filters.sobel_v`) versions of the Sobel filter.\n",
    "  * Check the results of other filters, `filters.roberts`, `filters.prewitt`, `filters.scharr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution goes here!\n",
    "plane_sobel_h = ...  # Horizontal Sobel.\n",
    "plane_sobel_v = ...  # Vertical Sobel.\n",
    "plane_roberts = ...  # Roberts.\n",
    "plane_prewitt = ...  # Prewitt.\n",
    "plane_scharr = ...  # Scharr.\n",
    "\n",
    "# Checking the results.\n",
    "_, ((win_top_left, win_top_center, win_top_right),\n",
    "    (win_bottom_left, win_bottom_center, win_bottom_right)) = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\n",
    "\n",
    "sc.show_plane(win_top_left, ..., title='Original')\n",
    "sc.show_plane(win_top_center, ..., title='Horizontal Sobel')\n",
    "sc.show_plane(win_top_right, ..., title='Vertical Sobel')\n",
    "\n",
    "sc.show_plane(win_bottom_left, ..., title='Roberts')\n",
    "sc.show_plane(win_bottom_center, ..., title='Prewitt')\n",
    "sc.show_plane(win_bottom_right, ..., title='Scharr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters\n",
    "\n",
    "[Gaussian filter](https://en.wikipedia.org/wiki/Gaussian_filter) applies a Gaussian function to an image, creating a smoothing effect. `skimage.filters.gaussian` takes as input `sigma` which can be a scalar or a sequence of scalar. This `sigma` determines the standard deviation of the Gaussian along each axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1.5\n",
    "\n",
    "plane_gaussian = filters.gaussian(plane_rescaled,\n",
    "                                  multichannel=False,\n",
    "                                  sigma=sigma)\n",
    "\n",
    "_, (win_left, win_right) = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "sc.show_plane(win_left, plane, title='Original');\n",
    "sc.show_plane(win_right, plane_gaussian, title='Gaussian');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Median filter](https://en.wikipedia.org/wiki/Median_filter) is a noise removal filter. It is particularly effective against salt and pepper noise. An additional feature of the median filter is its ability to preserve edges. This is helpful in segmentation because the original shape of regions of interest will be preserved.\n",
    "\n",
    "`skimage.filters.median` does not support three-dimensional images and needs to be applied planewise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_median = filters.median(plane_rescaled, behavior='ndimage')\n",
    "\n",
    "# Checking the results.\n",
    "_, (win_left, win_right) = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "sc.show_plane(win_left, plane, title='Original');\n",
    "sc.show_plane(win_right, plane_median, title='Median');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose the median-filtered image to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_denoised = plane_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__Exercise: <font color='red'>(‚è∞ 5 min)</font>__ the module `skimage.restoration` includes routines to restore images and reduce their noise.\n",
    "\n",
    "Now your tasks are:\n",
    "  * Use bilateral and Chambolle's total variation filters on the test image. They are in the functions `restoration.denoise_bilateral` and `restoration.denoise_tv_chambolle`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import restoration  # skimage's restoration submodule.\n",
    "\n",
    "plane_bilateral = restoration. ...\n",
    "plane_wiener = restoration. ...\n",
    "\n",
    "# Checking the results.\n",
    "_, (win_left, win_center, win_right) = plt.subplots(nrows=1, ncols=3, figsize=(12, 8))\n",
    "\n",
    "sc.show_plane(win_left, ..., title='Original')\n",
    "sc.show_plane(win_center, ..., title='Bilateral')\n",
    "sc.show_plane(win_right, ..., title='TV Chambolle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "\n",
    "[Thresholding](https://en.wikipedia.org/wiki/Thresholding_%28image_processing%29) is used to create binary images. A threshold value determines the intensity value separating foreground pixels from background pixels. Foregound pixels are pixels brighter than the threshold value, background pixels are darker. Thresholding is a form of image segmentation, and different thresholding algorithms produce different results.\n",
    "\n",
    "Let's try the Li's minimum cross entropy threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_li = filters.threshold_li(plane_denoised)\n",
    "plane_binary = plane_denoised >= threshold_li\n",
    "\n",
    "_, (win_left, win_center, win_right) = plt.subplots(nrows=1, ncols=3, figsize=(16, 5))\n",
    "\n",
    "# Checking the results.\n",
    "sc.show_plane(win_left, plane, title='Original')\n",
    "sc.show_plane(win_center, plane_binary, title='Li\\'s threshold = {:0.2}'.format(threshold_li))\n",
    "\n",
    "sc.plot_hist(win_right, plane_denoised, 'Histogram +\\n Li\\'s threshold (red line)')\n",
    "win_right.axvline(threshold_li, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__Exercise: <font color='red'>(‚è∞ 5 min)</font>__ There are lots of thresholding algorithms in scikit-image, and a function that helps you on trying some of them.\n",
    "\n",
    "Your task is:\n",
    "  * Use the function `filters.try_all_threshold` to try some different thresholds on our plane. Compare their results.\n",
    "  * Check the threshold values of each algorithm contained in that function. The functions have names such as `filters.threshold_*`; start typing and use the ``TAB`` key to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution goes here!\n",
    "filters.try_all_threshold(...)\n",
    "\n",
    "print(filters.threshold_isodata(plane_denoised))  # This one is for free!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='morphology'></a>[skimage.morphology](https://scikit-image.org/docs/stable/api/skimage.morphology.html) - binary and grayscale morphology\n",
    "\n",
    "Morphological image processing is a collection of non-linear operations related to the shape or morphology of features in an image, such as boundaries, skeletons, etc. In any given technique, we probe an image with a small shape or template called a structuring element, which defines the region of interest or neighborhood around a pixel.\n",
    "\n",
    "[Mathematical morphology](https://en.wikipedia.org/wiki/Mathematical_morphology) operations and structuring elements are defined in `skimage.morphology`. Structuring elements are shapes which define areas over which an operation is applied. The response to the filter indicates how well the neighborhood corresponds to the structuring element's shape.\n",
    "\n",
    "There are a number of two and three dimensional structuring elements defined in `skimage.morphology`. Not all 2D structuring element have a 3D counterpart. The simplest and most commonly used structuring elements are the `disk`/`ball` and `square`/`cube`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology  # skimage's morphological submodules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk = morphology.disk(radius=5)\n",
    "ball = morphology.ball(radius=5)\n",
    "print('* \"disk\" shape: {}\\n* \"ball\" shape: {}'.format(disk.shape, ball.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic mathematical morphology operations are `dilation` and `erosion`. Dilation enlarges bright regions and shrinks dark regions. Erosion shrinks bright regions and enlarges dark regions. Other morphological operations are composed of `dilation` and `erosion`.\n",
    "\n",
    "The `closing` of an image is defined as a `dilation` followed by an `erosion`. Closing can remove small dark spots (i.e. ‚Äúpepper‚Äù) and connect small bright cracks. This tends to ‚Äúclose‚Äù up (dark) gaps between (bright) features. Morphological `opening` on an image is defined as an `erosion` followed by a `dilation`. Opening can remove small bright spots (i.e. ‚Äúsalt‚Äù) and connect small dark cracks. This tends to ‚Äúopen‚Äù up (dark) gaps between (bright) features.\n",
    "\n",
    "These operations in `skimage.morphology` are compatible with 3D images and structuring elements. A 2D structuring element cannot be applied to a 3D image, nor can a 3D structuring element be applied to a 2D image.\n",
    "\n",
    "These four operations (`closing`, `dilation`, `erosion`, `opening`) have binary counterparts which are faster to compute than the grayscale algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selem = morphology.disk(radius=3)\n",
    "\n",
    "plane_binary_closing = morphology.binary_closing(plane_binary, selem=selem)\n",
    "plane_binary_dilation = morphology.binary_dilation(plane_binary, selem=selem)\n",
    "plane_binary_erosion = morphology.binary_erosion(plane_binary, selem=selem)\n",
    "plane_binary_opening = morphology.binary_opening(plane_binary, selem=selem)\n",
    "\n",
    "_, ((win_top_left, win_top_right),\n",
    "    (win_bottom_left, win_bottom_right)) = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "\n",
    "sc.show_plane(win_top_left, plane_binary_erosion, title='Binary erosion')\n",
    "sc.show_plane(win_top_right, plane_binary_dilation, title='Binary dilation')\n",
    "sc.show_plane(win_bottom_left, plane_binary_closing, title='Binary closing')\n",
    "sc.show_plane(win_bottom_right, plane_binary_opening, title='Binary opening')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morphology operations can be chained together to denoise an image. For example, a `closing` applied to an `opening` can remove salt and pepper noise from an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_binary_clipped = plane_rescaled >= filters.threshold_li(plane_clipped)\n",
    "\n",
    "plane_despeckled_radius1 = morphology.closing(\n",
    "    morphology.opening(plane_binary_clipped, selem=morphology.disk(1)),\n",
    "    selem=morphology.disk(1)\n",
    ")\n",
    "\n",
    "plane_despeckled_radius3 = morphology.closing(\n",
    "    morphology.opening(plane_binary_clipped, selem=morphology.disk(3)),\n",
    "    selem=morphology.disk(3)\n",
    ")\n",
    "\n",
    "_, (win_left, win_center, win_right) = plt.subplots(nrows=1, ncols=3, figsize=(16, 6))\n",
    "\n",
    "sc.show_plane(win_left, plane_binary_clipped, title='Noisy data')\n",
    "sc.show_plane(win_center, plane_despeckled_radius1, title='Despeckled, r = 1')\n",
    "sc.show_plane(win_right, plane_despeckled_radius3, title='Despeckled, r = 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions operating on [connected components](https://en.wikipedia.org/wiki/Connected_space) can remove small undesired elements while preserving larger shapes.\n",
    "\n",
    "`skimage.morphology.remove_small_holes` fills holes and `skimage.morphology.remove_small_objects` removes bright regions. Both functions accept a `min_size` parameter, which is the minimum size (in pixels) of accepted holes or objects. The `min_size` can be approximated by a cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 20\n",
    "\n",
    "plane_remove_holes = morphology.remove_small_holes(plane_binary,\n",
    "                                                   width ** 3)\n",
    "\n",
    "# Checking the results.\n",
    "_, (win_left, win_right) = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "sc.show_plane(win_left, plane_binary, title='Binary');\n",
    "sc.show_plane(win_right, plane_remove_holes, title='Removing holes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 50\n",
    "\n",
    "plane_remove_objects = morphology.remove_small_objects(plane_remove_holes,\n",
    "                                                       min_size=width)\n",
    "\n",
    "# Checking the results.\n",
    "_, (win_left, win_right) = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "sc.show_plane(win_left, plane_binary, title='Binary');\n",
    "sc.show_plane(win_right, plane_remove_objects, title='Removing holes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='measure'></a>[skimage.measure](https://scikit-image.org/docs/stable/api/skimage.measure.html) - measuring image or region properties\n",
    "\n",
    "Multiple algorithms to label images, or obtain information about discrete regions of an image.\n",
    "\n",
    "* `measure.label` - Label an image, i.e. identify discrete regions in the image using unique integers.\n",
    "* `measure.regionprops` - In a labeled image, as returned by `label`, find various properties of the labeled regions.\n",
    "\n",
    "Finding paths from a 2D image, or isosurfaces from a 3D image.\n",
    "\n",
    "* `measure.find_contours`\n",
    "* `measure.marching_cubes_lewiner`\n",
    "* `measure.marching_cubes_classic`\n",
    "* `measure.mesh_surface_area` - Surface area of 3D mesh from marching cubes.\n",
    "* `measure.compare_*` - Quantify the difference between two whole images; often used in denoising or restoration.\n",
    "\n",
    "**RANDom Sample Consensus fitting (RANSAC)** - a powerful, robust approach to fitting a model to data.  It exists here because its initial use was for fitting shapes, but it can also fit transforms.\n",
    "* `measure.ransac`\n",
    "* `measure.CircleModel`\n",
    "* `measure.EllipseModel`\n",
    "* `measure.LineModelND`\n",
    "\n",
    "[Image segmentation](https://en.wikipedia.org/wiki/Image_segmentation) partitions images into regions of interest. Integer labels are assigned to each region to distinguish regions of interest.\n",
    "\n",
    "Connected components of the binary image are assigned the same label via `skimage.measure.label`. Tightly packed cells  connected in the binary image are assigned the same label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure  # skimage's measure submodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_labels = measure.label(plane_remove_objects)\n",
    "\n",
    "# Checking the results.\n",
    "_, (win_left, win_center, win_right) = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "\n",
    "sc.show_plane(win_left, plane, title='Original')\n",
    "sc.show_plane(win_center, plane_labels, cmap='nipy_spectral', title='Labels')\n",
    "sc.show_plane(win_right, plane_labels == 8, title='Label = 8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better segmentation would assign different labels to disjoint regions in the original image. \n",
    "\n",
    "[Watershed segmentation](https://en.wikipedia.org/wiki/Watershed_%28image_processing%29) can distinguish touching objects. Markers are placed at local minima and expanded outward until there is a collision with markers from another region. The inverse intensity image transforms bright cell regions into basins which should be filled.\n",
    "\n",
    "In declumping, markers are generated from the distance function. Points furthest from an edge have the highest intensity and should be identified as markers using `skimage.feature.peak_local_max`. Regions with pinch points should be assigned multiple markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_distance = ndimage.distance_transform_edt(plane_remove_objects)\n",
    "\n",
    "_, win = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "sc.show_plane(win, plane_distance, cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [skimage.feature](https://scikit-image.org/docs/stable/api/skimage.feature.html) - extract features from an image<a id='feature'></a>\n",
    "\n",
    "This submodule presents a diverse set of tools to identify or extract certain features from images, including tools for\n",
    "\n",
    "* Edge detection: `feature.canny`\n",
    "* Corner detection:\n",
    "  * `feature.corner_kitchen_rosenfeld`\n",
    "  * `feature.corner_harris`\n",
    "  * `feature.corner_shi_tomasi`\n",
    "  * `feature.corner_foerstner`\n",
    "  * `feature.subpix`\n",
    "  * `feature.corner_moravec`\n",
    "  * `feature.corner_fast`\n",
    "  * `feature.corner_orientations`\n",
    "* Blob detection\n",
    "  * `feature.blob_dog`\n",
    "  * `feature.blob_doh`\n",
    "  * `feature.blob_log`\n",
    "* Texture\n",
    "  * `feature.greycomatrix`\n",
    "  * `feature.greycoprops`\n",
    "  * `feature.local_binary_pattern`\n",
    "  * `feature.multiblock_lbp`\n",
    "* Peak finding: `feature.peak_local_max`\n",
    "* Object detction\n",
    "  * `feature.hog`\n",
    "  * `feature.match_template`\n",
    "* Stereoscopic depth estimation: `feature.daisy`\n",
    "* Feature matching\n",
    "  * `feature.ORB`\n",
    "  * `feature.BRIEF`\n",
    "  * `feature.CENSURE`\n",
    "  * `feature.match_descriptors`\n",
    "  * `feature.plot_matches`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature  # skimage's feature submodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_local_max = feature.peak_local_max(\n",
    "    plane_distance,\n",
    "    footprint=np.ones((15, 15), dtype=np.bool),\n",
    "    indices=False,\n",
    "    labels=measure.label(plane_remove_objects)\n",
    ")\n",
    "\n",
    "plane_markers = measure.label(peak_local_max)\n",
    "\n",
    "plane_labels = morphology.watershed(\n",
    "    plane_rescaled, \n",
    "    plane_markers, \n",
    "    mask=plane_remove_objects\n",
    ")\n",
    "\n",
    "# Checking the results.\n",
    "_, (win_left, win_right) = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "sc.show_plane(win_left, plane, title='Original')\n",
    "sc.show_plane(win_right, plane_labels, cmap='nipy_spectral', title='Watershed labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After watershed, we have better disambiguation between internal cells.\n",
    "\n",
    "The watershed algorithm falsely detected subregions in a few cells. This is referred to as oversegmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axis = plt.subplots(figsize=(12, 8))\n",
    "sc.show_plane(axis, plane_labels[50:100, 20:100], cmap='nipy_spectral', title='Oversegmented labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the markers on the distance image reveals the reason for oversegmentation. Cells with multiple markers will be assigned multiple labels, and oversegmented. It can be observed that cells with a uniformly increasing distance map are assigned a single marker near their center. Cells with uneven distance maps are assigned multiple markers, indicating the presence of multiple local maxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(nrows=1, ncols=1, figsize=(16, 12))\n",
    "\n",
    "vmin = plane_distance.min()\n",
    "vmax = plane_distance.max()\n",
    "\n",
    "ax.imshow(plane_distance, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    \n",
    "peaks = np.nonzero(peak_local_max)\n",
    "    \n",
    "ax.plot(peaks[1], peaks[0], 'r.')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (win_left, win_center, win_right) = plt.subplots(nrows=1, ncols=3, figsize=(16, 8))\n",
    "\n",
    "sc.show_plane(win_left, plane_remove_objects[10:100, 190:253])\n",
    "sc.show_plane(win_center, plane_distance[10:100, 190:253])\n",
    "\n",
    "features = feature.peak_local_max(plane_distance[10:100, 190:253])\n",
    "win_center.plot(features[:, 1], features[:, 0], 'r.')\n",
    "\n",
    "# Improve feature selection by blurring, using a larger footprint\n",
    "# in `peak_local_max`, etc.\n",
    "\n",
    "smooth_distance = filters.gaussian(plane_distance[10:100, 190:253], sigma=10)\n",
    "sc.show_plane(win_right, smooth_distance)\n",
    "features = feature.peak_local_max(\n",
    "    smooth_distance\n",
    ")\n",
    "win_right.plot(features[:, 1], features[:, 0], 'bx');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_distance = filters.gaussian(plane_distance, sigma=10)\n",
    "peak_local_max = feature.peak_local_max(\n",
    "    smooth_distance,\n",
    "    footprint=np.ones((7, 7), dtype=np.bool),\n",
    "    indices=False,\n",
    "    labels=measure.label(plane_remove_objects)\n",
    ")\n",
    "\n",
    "plane_markers = measure.label(peak_local_max)\n",
    "\n",
    "plane_labels = morphology.watershed(\n",
    "    plane_rescaled, \n",
    "    plane_markers, \n",
    "    mask=plane_remove_objects\n",
    ")\n",
    "\n",
    "# Checking the results.\n",
    "_, (win_left, win_right) = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "sc.show_plane(win_left, plane, title='Original')\n",
    "sc.show_plane(win_right, plane_labels, cmap='nipy_spectral', title='Watershed labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__Exercise: <font color='red'>(‚è∞ 5 min)</font>__ Please help me generate a better result!\n",
    "\n",
    "Your task is:\n",
    "  * Change `sigma` and `footprint` to generate a better segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_distance = filters.gaussian(plane_distance, sigma=...)\n",
    "peak_local_max = feature.peak_local_max(\n",
    "    smooth_distance,\n",
    "    footprint=np.ones(..., dtype=np.bool),\n",
    "    indices=False,\n",
    "    labels=measure.label(plane_remove_objects)\n",
    ")\n",
    "\n",
    "plane_markers = measure.label(peak_local_max)\n",
    "\n",
    "plane_labels = morphology.watershed(\n",
    "    plane_rescaled, \n",
    "    plane_markers, \n",
    "    mask=plane_remove_objects\n",
    ")\n",
    "\n",
    "# Checking the results.\n",
    "_, (win_left, win_right) = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "sc.show_plane(win_left, plane, title='Original')\n",
    "sc.show_plane(win_right, plane_labels, cmap='nipy_spectral', title='Watershed labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='segmentation'></a>[skimage.segmentation](https://scikit-image.org/docs/stable/api/skimage.segmentation.html) - identification of regions of interest\n",
    "\n",
    "One of the key image analysis tasks is identifying regions of interest.  These could be a person, an object, certain features of an animal, microscopic image, or stars.  Segmenting an image is the process of determining where these things you want are in your images.\n",
    "\n",
    "Segmentation has two overarching categories:\n",
    "\n",
    "**Supervised** - must provide some guidance (seed points or initial conditions)\n",
    "\n",
    "* `segmentation.random_walker`\n",
    "* `segmentation.active_contour`\n",
    "* `segmentation.watershed`\n",
    "* `segmentation.flood_fill`\n",
    "* `segmentation.flood`\n",
    "\n",
    "**Unsupervised** - no human input\n",
    "\n",
    "* `segmentation.slic`\n",
    "* `segmentation.felzenszwalb`\n",
    "* `segmentation.chan_vese`\n",
    "\n",
    "There are also some supervised and unsupervised thresholding algorithms in `filters`. There is a [segmentation lecture](https://github.com/scikit-image/skimage-tutorials/blob/master/lectures/4_segmentation.ipynb) ([and its solution](https://github.com/scikit-image/skimage-tutorials/blob/master/lectures/solutions/4_segmentation.ipynb)) you may peruse, as well as many [gallery examples](https://scikit-image.org/docs/stable/auto_examples/index.html#segmentation-of-objects) which illustrate all of these segmentation methods.\n",
    "\n",
    "[Feature extraction](https://en.wikipedia.org/wiki/Feature_extraction) reduces data required to describe an image or objects by measuring informative features. These include features such as area or volume, bounding boxes, and intensity statistics.\n",
    "\n",
    "Before measuring objects, it helps to clear objects from the image border. Measurements should only be collected for objects entirely contained in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import segmentation  # skimage's segmentation submodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_labels_inner = segmentation.clear_border(plane_labels)\n",
    "plane_labels_inner = morphology.remove_small_objects(plane_labels_inner, min_size=200)\n",
    "\n",
    "print('Interior labels: {}'.format(np.unique(plane_labels_inner)))\n",
    "\n",
    "_, axis = plt.subplots(nrows=1, ncols=1, figsize=(12, 8))\n",
    "sc.show_plane(axis, plane_labels_inner, cmap='nipy_spectral');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After clearing the border, the object labels are no longer sequentially increasing. The labels can be renumbered such that there are no jumps in the list of image labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_relabeled, _, _ = segmentation.relabel_sequential(plane_labels_inner)\n",
    "\n",
    "print('Relabeled labels: {}'.format(np.unique(plane_relabeled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skimage.measure.regionprops` automatically measures many labeled image features. Optionally, an `intensity_image` can be supplied and intensity features are extracted per object. It's good practice to make measurements on the original image.\n",
    "\n",
    "The list below shows supported 2D measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = measure.regionprops(plane_relabeled, intensity_image=plane)\n",
    "props_first_region = properties[0]\n",
    "\n",
    "supported = [''] \n",
    "\n",
    "for prop in props_first_region:\n",
    "    try:\n",
    "        props_first_region[prop]\n",
    "        supported.append(prop)\n",
    "    except NotImplementedError:\n",
    "        pass\n",
    "\n",
    "print('Supported 2D properties:')\n",
    "print('\\n\\t'.join(supported))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skimage.measure.regionprops` ignores the 0 label, which represents the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Measured regions: {}'.format([prop.label for prop in properties]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_areas = [prop.area for prop in properties]\n",
    "\n",
    "print('Total pixels: {}'.format(plane_areas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collected measurements can be further reduced by computing per-image statistics such as total, minimum, maximum, mean, and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Area statistics\\n')\n",
    "print(' * Total: {}'.format(np.sum(plane_areas)))\n",
    "print(' * Min: {}'.format(np.min(plane_areas)))\n",
    "print(' * Max: {}'.format(np.max(plane_areas)))\n",
    "print(' * Mean: {:0.2f}'.format(np.mean(plane_areas)))\n",
    "print(' * Standard deviation: {:0.2f}'.format(np.std(plane_areas)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__Exercise: <font color='red'>(‚è∞ 5 min)</font>__ Let's check other properties.\n",
    "\n",
    "Your task is:\n",
    "  * Use `regionprops` and check other properties for the labeled regions. Some examples: `centroid` and `equivalent_diameter`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going beyond\n",
    "\n",
    "[1] A tour/guide on scikit-image's submodules: https://github.com/scikit-image/skimage-tutorials/blob/master/lectures/tour_of_skimage.ipynb\n",
    "\n",
    "[2] scikit-image's gallery examples: https://scikit-image.org/docs/stable/auto_examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
