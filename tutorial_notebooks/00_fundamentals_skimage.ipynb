{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright (C) 2019, Daniela Ushizima, Alexandre de Siqueira and Stéfan van der Walt\n",
    "All rights reserved.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without\n",
    "modification, are permitted provided that the following conditions are\n",
    "met:\n",
    "\n",
    " 1. Redistributions of source code must retain the above copyright\n",
    "    notice, this list of conditions and the following disclaimer.\n",
    " 2. Redistributions in binary form must reproduce the above copyright\n",
    "    notice, this list of conditions and the following disclaimer in\n",
    "    the documentation and/or other materials provided with the\n",
    "    distribution.\n",
    " 3. Neither the name of skimage nor the names of its contributors may be\n",
    "    used to endorse or promote products derived from this software without\n",
    "    specific prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n",
    "IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n",
    "WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "DISCLAIMED. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT,\n",
    "INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n",
    "(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n",
    "HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,\n",
    "STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING\n",
    "IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "POSSIBILITY OF SUCH DAMAGE.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and visualization of 3D data in Python\n",
    "\n",
    "Daniela Ushizima, Alexandre de Siqueira, Stéfan van der Walt\\\n",
    "14th International Symposium on Visual Computing\\\n",
    "Lake Tahoe, NV, USA\\\n",
    "October 7-9, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import supplementary_code as sc\n",
    "\n",
    "from ipywidgets import interact\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection, Line3DCollection\n",
    "from scipy import ndimage as ndi\n",
    "from scipy import stats\n",
    "\n",
    "from skimage import (color, data, exposure, feature, filters, io, measure,\n",
    "                    morphology, restoration, segmentation, transform,\n",
    "                    util)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-image: a tour\n",
    "\n",
    "There are many tools and utilities in the package, far too many to cover in a tutorial. This notebook is designed as a \n",
    "road map, to guide you as you explore or search for additional tools for your applications.\n",
    "\n",
    "Each submodule of scikit-image has its own section, which you can navigate to below:\n",
    "\n",
    "* [skimage.color](#color)\n",
    "* [skimage.data](#data)\n",
    "* [skimage.draw](#draw)\n",
    "* [skimage.exposure](#exposure)\n",
    "* [skimage.feature](#feature)\n",
    "* [skimage.filters](#filters)\n",
    "* [skimage.future](#future)\n",
    "* [skimage.graph](#graph)\n",
    "* [skimage.io](#io)\n",
    "* [skimage.measure](#measure)\n",
    "* [skimage.morphology](#morphology)\n",
    "* [skimage.restoration](#restoration)\n",
    "* [skimage.segmentation](#segmentation)\n",
    "* [skimage.transform](#transform)\n",
    "* [skimage.util](#util)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [skimage.color](https://scikit-image.org/docs/stable/api/skimage.color.html) - color conversion<a id='color'></a>\n",
    "\n",
    "The `color` submodule includes routines to convert to and from common color representations.  For example, RGB (Red, Green, and Blue) can be converted into many other representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [skimage.data](https://scikit-image.org/docs/stable/api/skimage.data.html) - test images<a id='data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `data` submodule includes standard test images useful for examples and testing the package.  These images are shipped with the package.\n",
    "\n",
    "There are scientific images, general test images, and a stereoscopic image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [skimage.draw](https://scikit-image.org/docs/stable/api/skimage.draw.html) - drawing primitives on an image<a id='draw'></a>\n",
    "\n",
    "The majority of functions in this submodule return the *coordinates* of the specified shape/object in the image, rather than drawing it on the image directly.  The coordinates can then be used as a mask to draw on the image, or you pass the image as well as those coordinates into the convenience function `draw.set_color`.\n",
    "\n",
    "Lines and circles can be drawn with antialiasing (these functions end in the suffix `*_aa`).\n",
    "\n",
    "At the current time text is not supported; other libraries including matplotlib have robust support for overlaying text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [skimage.exposure](https://scikit-image.org/docs/stable/api/skimage.exposure.html) - evaluating or changing the exposure of an image<a id='exposure'></a>\n",
    "\n",
    "One of the most common tools to evaluate exposure is the *histogram*, which plots the number of points which have a certain value against the values in order from lowest (dark) to highest (light).  The function `exposure.histogram` differs from `numpy.histogram` in that there is no rebinnning; each value along the x-axis is preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [skimage.feature](https://scikit-image.org/docs/stable/api/skimage.feature.html) - extract features from an image<a id='feature'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submodule presents a diverse set of tools to identify or extract certain features from images, including tools for\n",
    "\n",
    "* Edge detection\n",
    "  * `feature.canny`\n",
    "* Corner detection\n",
    "  * `feature.corner_kitchen_rosenfeld`\n",
    "  * `feature.corner_harris`\n",
    "  * `feature.corner_shi_tomasi`\n",
    "  * `feature.corner_foerstner`\n",
    "  * `feature.subpix`\n",
    "  * `feature.corner_moravec`\n",
    "  * `feature.corner_fast`\n",
    "  * `feature.corner_orientations`\n",
    "* Blob detection\n",
    "  * `feature.blob_dog`\n",
    "  * `feature.blob_doh`\n",
    "  * `feature.blob_log`\n",
    "* Texture\n",
    "  * `feature.greycomatrix`\n",
    "  * `feature.greycoprops`\n",
    "  * `feature.local_binary_pattern`\n",
    "  * `feature.multiblock_lbp`\n",
    "* Peak finding\n",
    "  * `feature.peak_local_max`\n",
    "* Object detction\n",
    "  * `feature.hog`\n",
    "  * `feature.match_template`\n",
    "* Stereoscopic depth estimation\n",
    "  * `feature.daisy`\n",
    "* Feature matching\n",
    "  * `feature.ORB`\n",
    "  * `feature.BRIEF`\n",
    "  * `feature.CENSURE`\n",
    "  * `feature.match_descriptors`\n",
    "  * `feature.plot_matches`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [skimage.filters](https://scikit-image.org/docs/stable/api/skimage.filters.html) - apply filters to an image<a id='filters'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering applies whole-image modifications such as sharpening or blurring.  Thresholding methods also live in this submodule.\n",
    "\n",
    "Notable functions include (links to relevant gallery examples)\n",
    "\n",
    "* [Thresholding](https://scikit-image.org/docs/stable/auto_examples/applications/plot_thresholding.html)\n",
    "  * `filters.threshold_*` (multiple different functions with this prefix)\n",
    "  * `filters.try_all_threshold` to compare various methods\n",
    "* [Edge finding/enhancement](https://scikit-image.org/docs/stable/auto_examples/edges/plot_edge_filter.html)\n",
    "  * `filters.sobel`\n",
    "  * `filters.prewitt`\n",
    "  * `filters.scharr`\n",
    "  * `filters.roberts`\n",
    "  * `filters.laplace`\n",
    "  * `filters.hessian`\n",
    "* [Ridge filters](https://scikit-image.org/docs/stable/auto_examples/edges/plot_ridge_filter.html)\n",
    "  * `filters.meijering`\n",
    "  * `filters.sato`\n",
    "  * `filters.frangi`\n",
    "* Inverse filtering (see also [skimage.restoration](#restoration))\n",
    "  * `filters.weiner`\n",
    "  * `filters.inverse`\n",
    "* [Directional](https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_gabor.html)\n",
    "  * `filters.gabor`\n",
    "* Blurring/denoising\n",
    "  * `filters.gaussian`\n",
    "  * `filters.median`\n",
    "* [Sharpening](https://scikit-image.org/docs/stable/auto_examples/filters/plot_unsharp_mask.html)\n",
    "  * `filters.unsharp_mask`\n",
    "* Define your own\n",
    "  * `LPIFilter2D`\n",
    "  \n",
    "There is a sub-submodule, `skimage.filters.rank`, which contains rank filters.  These filters are nonlinear and operate on the local histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [skimage.future](https://scikit-image.org/docs/stable/api/skimage.future.html) - stable code with unstable API<a id='future'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bleeding edge features which work well, and will be moved from here into the main package in future releases.  However, on the way their API may change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [skimage.graph](https://scikit-image.org/docs/stable/api/skimage.graph.html) - graph theory, minimum cost paths<a id='graph'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph theory. Currently this submodule primarily deals with a constructed \"cost\" image, and how to find the minimum cost path through it, with constraints if desired. The [panorama tutorial](./solutions/adv3_panorama-stitching-solution.ipynb) lecture illustrates a real-world example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [skimage.io](https://scikit-image.org/docs/stable/api/skimage.io.html) - utilities to read and write images in various formats<a id='io'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading your image and writing the results back out.  There are multiple plugins available, which support multiple formats.  The most commonly used functions include\n",
    "\n",
    "* `io.imread` - Read an image to a numpy array.\n",
    "* `io.imsave` - Write an image to disk.\n",
    "* `io.imread_collection` - Read multiple images which match a common prefix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='measure'></a>[skimage.measure](https://scikit-image.org/docs/stable/api/skimage.measure.html) - measuring image or region properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple algorithms to label images, or obtain information about discrete regions of an image.\n",
    "\n",
    "* `measure.label` - Label an image, i.e. identify discrete regions in the image using unique integers.\n",
    "* `measure.regionprops` - In a labeled image, as returned by `label`, find various properties of the labeled regions.\n",
    "\n",
    "Finding paths from a 2D image, or isosurfaces from a 3D image.\n",
    "\n",
    "* `measure.find_contours`\n",
    "* `measure.marching_cubes_lewiner`\n",
    "* `measure.marching_cubes_classic`\n",
    "* `measure.mesh_surface_area` - Surface area of 3D mesh from marching cubes.\n",
    "* `measure.compare_*` - Quantify the difference between two whole images; often used in denoising or restoration.\n",
    "\n",
    "**RANDom Sample Consensus fitting (RANSAC)** - a powerful, robust approach to fitting a model to data.  It exists here because its initial use was for fitting shapes, but it can also fit transforms.\n",
    "* `measure.ransac`\n",
    "* `measure.CircleModel`\n",
    "* `measure.EllipseModel`\n",
    "* `measure.LineModelND`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='morphology'></a>[skimage.morphology](https://scikit-image.org/docs/stable/api/skimage.morphology.html) - binary and grayscale morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morphological image processing is a collection of non-linear operations related to the shape or morphology of features in an image, such as boundaries, skeletons, etc. In any given technique, we probe an image with a small shape or template called a structuring element, which defines the region of interest or neighborhood around a pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [skimage.restoration](https://scikit-image.org/docs/stable/api/skimage.restoration.html) - restoration of an image<a id='restoration'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submodule includes routines to restore images.  Currently these routines fall into four major categories.  Links lead to topical gallery examples.\n",
    "\n",
    "* `restoration.denoise_*` - [Reducing noise](https://scikit-image.org/docs/stable/auto_examples/filters/plot_denoise.html).\n",
    "* [Deconvolution](https://scikit-image.org/docs/stable/auto_examples/filters/plot_deconvolution.html), or reversing a convolutional effect which applies to the entire image. This can be done in an [unsupervised](https://scikit-image.org/docs/stable/auto_examples/filters/plot_restoration.html) way.\n",
    "  * `restoration.weiner`\n",
    "  * `restoration.unsupervised_weiner`\n",
    "  * `restoration.richardson_lucy`\n",
    "* `restoration.inpaint_biharmonic` - [Inpainting](https://scikit-image.org/docs/stable/auto_examples/filters/plot_inpaint.html), or filling in missing areas of an image.\n",
    "* `restoration.unwrap_phase` - [Phase unwrapping](https://scikit-image.org/docs/stable/auto_examples/filters/plot_phase_unwrap.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='segmentation'></a>[skimage.segmentation](https://scikit-image.org/docs/stable/api/skimage.segmentation.html) - identification of regions of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the key image analysis tasks is identifying regions of interest.  These could be a person, an object, certain features of an animal, microscopic image, or stars.  Segmenting an image is the process of determining where these things you want are in your images.\n",
    "\n",
    "Segmentation has two overarching categories:\n",
    "\n",
    "**Supervised** - must provide some guidance (seed points or initial conditions)\n",
    "\n",
    "* `segmentation.random_walker`\n",
    "* `segmentation.active_contour`\n",
    "* `segmentation.watershed`\n",
    "* `segmentation.flood_fill`\n",
    "* `segmentation.flood`\n",
    "* some thresholding algorithms in `filters`\n",
    "\n",
    "\n",
    "**Unsupervised** - no human input\n",
    "\n",
    "* `segmentation.slic`\n",
    "* `segmentation.felzenszwalb`\n",
    "* `segmentation.chan_vese`\n",
    "* some thresholding algorithms in `filters`\n",
    "\n",
    "\n",
    "There is a [segmentation lecture](./4_segmentation.ipynb) ([and solution](./solutions/4_segmentation.ipynb)) you may peruse, as well as many [gallery examples](https://scikit-image.org/docs/stable/auto_examples/index.html#segmentation-of-objects) which illustrate all of these segmentation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [skimage.transform](https://scikit-image.org/docs/stable/api/skimage.transform.html) - transforms & warping<a id='transform'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submodule has multiple features which fall under the umbrella of transformations.\n",
    "\n",
    "Forward (`radon`) and inverse (`iradon`) radon transforms, as well as some variants (`iradon_sart`) and the finite versions of these transforms (`frt2` and `ifrt2`).  These are used for [reconstructing medical computed tomography (CT) images](https://scikit-image.org/docs/stable/auto_examples/transform/plot_radon_transform.html).\n",
    "\n",
    "Hough transforms for identifying lines, circles, and ellipses.\n",
    "\n",
    "Changing image size, shape, or resolution with `resize`, `rescale`, or `downscale_local_mean`.\n",
    "\n",
    "`warp`, and `warp_coordinates` which take an image or set of coordinates and translate them through one of the defined `*Transforms` in this submodule.  `estimate_transform` may be assist in estimating the parameters.\n",
    "\n",
    "[Numerous gallery examples are available](https://scikit-image.org/docs/stable/auto_examples/index.html#geometrical-transformations-and-registration) illustrating these functions.  [The panorama tutorial also includes warping](./solutions/adv3_panorama-stitching-solution.ipynb) via `SimilarityTransform` with parameter estimation via `measure.ransac`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [skimage.util](https://scikit-image.org/docs/stable/api/skimage.util.html) - utility functions<a id='util'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are generally useful functions which have no definite other place in the package.\n",
    "\n",
    "`util.img_as_*` are convenience functions for datatype conversion.\n",
    "\n",
    "`util.invert` is a convenient way to invert any image, accounting for its datatype.\n",
    "\n",
    "`util.random_noise` is a comprehensive function to apply any amount of many different types of noise to images.  The seed may be set, resulting in pseudo-random noise for testing.\n",
    "\n",
    "`util.view_as_*` allows for overlapping views into the same memory array, which is useful for elegant local computations with minimal memory impact.\n",
    "\n",
    "`util.apply_parallel` uses Dask to apply a function across subsections of an image.  This can result in dramatic performance or memory improvements, but depending on the algorithm edge effects or lack of knowledge of the remainder of the image may result in unexpected results.\n",
    "\n",
    "`util.pad` and `util.crop` pads or crops the edges of images.  `util.pad` is now a direct wrapper for `numpy.pad`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to three-dimensional image processing\n",
    "\n",
    "Images are represented as `numpy` arrays. A single-channel, or grayscale, image is a 2D matrix of pixel intensities of shape `(row, column)`. We can construct a 3D volume as a series of 2D `planes`, giving 3D images the shape `(plane, row, column)`. Multichannel data adds a `channel` dimension in the final position containing color information. \n",
    "\n",
    "These conventions are summarized in the table below:\n",
    "\n",
    "\n",
    "|Image type|Coordinates|\n",
    "|:---|:---|\n",
    "|2D grayscale|(row, column)|\n",
    "|2D multichannel|(row, column, channel)|\n",
    "|3D grayscale|(plane, row, column)|\n",
    "|3D multichannel|(plane, row, column, channel)|\n",
    "\n",
    "Some 3D images are constructed with equal resolution in each dimension; e.g., a computer generated rendering of a sphere. Most experimental data captures one dimension at a lower resolution than the other two; e.g., photographing thin slices to approximate a 3D structure as a stack of 2D images.\n",
    "## Input/Output and display\n",
    "\n",
    "Three dimensional data can be loaded with `skimage.io.imread`. The data for this tutorial was provided by the Allen Institute for Cell Science. It has been downsampled by a factor of 4 in the `row` and `column` dimensions to reduce computational time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Data shape: (60, 256, 256)\n",
      "* Data type:  float64\n",
      "* Data range: (0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "data = io.imread(\"images/cells.tif\")\n",
    "\n",
    "print(f\"* Data shape: {data.shape}\")\n",
    "print(f\"* Data type:  {data.dtype}\")\n",
    "print(f\"* Data range: ({data.min()}, {data.max()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to our original data, let's try visualizing the image with `skimage.io.imshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    io.imshow(data, cmap=\"gray\")\n",
    "except TypeError as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skimage.io.imshow` can only display grayscale and RGB(A) 2D images. We can use `skimage.io.imshow` to visualize 2D planes. By fixing one axis, we can observe three different views of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (a, b, c) = plt.subplots(nrows=1, ncols=3, figsize=(16, 4))\n",
    "\n",
    "sc.show_plane(a, data[32], title=\"Plane = 32\")\n",
    "sc.show_plane(b, data[:, 128, :], title=\"Row = 128\")\n",
    "sc.show_plane(c, data[:, :, 128], title=\"Column = 128\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three-dimensional images can be viewed as a series of two-dimensional functions. The `display` helper function displays 30 planes of the provided image. By default, every other plane is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.slice_explorer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exposure\n",
    "\n",
    "`skimage.exposure` contains a number of functions for adjusting image contrast. These functions operate on pixel values. Generally, image dimensionality or pixel spacing does not need to be considered.\n",
    "\n",
    "[Gamma correction](https://en.wikipedia.org/wiki/Gamma_correction), also known as Power Law Transform, brightens or darkens an image. The function $O = I^\\gamma$ is applied to each pixel in the image. A `gamma < 1` will brighten an image, while a `gamma > 1` will darken an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_low_val = 0.5\n",
    "gamma_low = exposure.adjust_gamma(data, gamma=gamma_low_val)\n",
    "\n",
    "gamma_high_val = 1.5\n",
    "gamma_high = exposure.adjust_gamma(data, gamma=gamma_high_val)\n",
    "\n",
    "_, ((a, b, c), (d, e, f)) = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\n",
    "\n",
    "sc.show_plane(a, data[32], title=\"Original\")\n",
    "sc.show_plane(b, gamma_low[32], title=\"Gamma = {}\".format(gamma_low_val))\n",
    "sc.show_plane(c, gamma_high[32], title=\"Gamma = {}\".format(gamma_high_val))\n",
    "\n",
    "sc.plot_hist(d, data)\n",
    "sc.plot_hist(e, gamma_low)\n",
    "sc.plot_hist(f, gamma_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Histogram equalization](https://en.wikipedia.org/wiki/Histogram_equalization) improves contrast in an image by redistributing pixel intensities. The most common pixel intensities are spread out, allowing areas of lower local contrast to gain a higher contrast. This may enhance background noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized = exposure.equalize_hist(data)\n",
    "\n",
    "sc.slice_explorer(equalized)\n",
    "\n",
    "_, ((a, b), (c, d)) = plt.subplots(nrows=2, ncols=2, figsize=(16, 8))\n",
    "\n",
    "sc.plot_hist(a, data, title=\"Original\")\n",
    "sc.plot_hist(b, equalized, title=\"Histogram equalization\")\n",
    "\n",
    "cdf, bins = exposure.cumulative_distribution(data.ravel())\n",
    "c.plot(bins, cdf, \"r\")\n",
    "c.set_title(\"Original CDF\")\n",
    "\n",
    "cdf, bins = exposure.cumulative_distribution(equalized.ravel())\n",
    "d.plot(bins, cdf, \"r\")\n",
    "d.set_title(\"Histogram equalization CDF\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most experimental images are affected by salt and pepper noise. A few bright artifacts can decrease the relative intensity of the pixels of interest. A simple way to improve contrast is to clip the pixel values on the lowest and highest extremes. Clipping the darkest and brightest 0.5% of pixels will increase the overall contrast of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = stats.scoreatpercentile(data, (0.5, 99.5))\n",
    "\n",
    "clipped = exposure.rescale_intensity(\n",
    "    data, \n",
    "    in_range=(vmin, vmax), \n",
    "    out_range=np.float32\n",
    ")\n",
    "\n",
    "sc.slice_explorer(clipped);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll call our dataset \"rescaled\" from here on\n",
    "# In this cell, you can choose any of the previous results\n",
    "# to continue working with.\n",
    "#\n",
    "# We'll use the `clipped` version\n",
    "#\n",
    "rescaled = clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
